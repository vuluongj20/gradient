import HeroImage from './heroImage'

<Header>

# Relational Learning with Conditional Random Fields

<Abstract>
  Probabilistic graphical models like Conditional Random Fields are powerful frameworks
  for solving sequence modeling problems.
</Abstract>

</Header>

<HeroImage />

Natural language is sequential by nature, characterized by complex syntactic structures that create meaning out of otherwise independent components. Consider the following sentence:

> _The Williamses live in a beautiful apartment building._

Here, the word apartment acts as an adjective that modifies building. However, if we remove building from the sentence, apartment would assume its normal role as a noun and the whole phrase would still make sense. This sort of location-specific role-switching and interdependency between words is incredibly common within the English language, as well as many other languages.

That fact presents a unique challenge to natural language models. How can a probabilistic model account for the non-linear, interdependent nature of words? Consider the problem of part-of-speech tagging: given a sequence of words in a sentence, we want to assign a part-of-speech label (noun, pronoun, verb, adjective,â€¦) to each of the words.
